{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "H:\\My Drive\\projects\\table-qa-in-ecommerce\n"
     ]
    }
   ],
   "source": [
    "cd \"H:\\My Drive\\projects\\table-qa-in-ecommerce\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install rank_bm25 -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install nltk -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\NamFam\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers\\punkt.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from rank_bm25 import BM25Okapi\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "# Function to load data from a JSON Lines file\n",
    "def load_data(file_path):\n",
    "    data = []\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        for line in file:\n",
    "            data.append(json.loads(line))\n",
    "    return data\n",
    "\n",
    "# Function to preprocess and tokenize text\n",
    "def tokenize(text):\n",
    "    return word_tokenize(text.lower())\n",
    "\n",
    "# Create the BM25 index from the product data\n",
    "def create_index(data):\n",
    "    corpus = []\n",
    "    product_ids = []\n",
    "    for product in data:\n",
    "        # Concatenate all textual content that should be searchable\n",
    "        content = ' '.join([product.get('product_id', ''),\n",
    "                            product.get('tên sản phẩm', ''),\n",
    "                            product.get('thông tin chung', {}).get('Chất liệu', ''),\n",
    "                            str(product.get('thông số kỹ thuật', {}).get('Màn hình', {}))])\n",
    "        corpus.append(tokenize(content))\n",
    "        product_ids.append(product['product_id'])\n",
    "    bm25 = BM25Okapi(corpus)\n",
    "    return bm25, product_ids\n",
    "\n",
    "# Query the index and retrieve products\n",
    "def query_index(bm25, product_ids, query, top_n=10):\n",
    "    tokenized_query = tokenize(query)\n",
    "    scores = bm25.get_scores(tokenized_query)\n",
    "    top_indexes = sorted(range(len(scores)), key=lambda i: scores[i], reverse=True)[:top_n]\n",
    "    return [product_ids[i] for i in top_indexes]\n",
    "\n",
    "# Load the data (replace 'path_to_your_data.jsonl' with the actual file path)\n",
    "data = load_data('data/tgdd_data/products/phone_products_20240406_203410_cleaned.json')\n",
    "\n",
    "# Create the index\n",
    "bm25, product_ids = create_index(data)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "Top matching products for your query: ['phone-nokia-8210-4g', 'phone-itel-it9210', 'phone-mobell-m331', 'phone-itel-it9010', 'phone-mobell-m239', 'phone-nokia-110-4g-pro', 'phone-nokia-105-4g-pro', 'phone-nokia-105-4g', 'phone-mobell-m539', 'phone-mobell-f209']\n"
     ]
    }
   ],
   "source": [
    "# Example query\n",
    "query = \"Điện thoại nào có điểm đánh giá trung bình lớn hơn 3.6\"\n",
    "results = query_index(bm25, product_ids, query)\n",
    "print(len(results))\n",
    "print(\"Top matching products for your query:\", results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score for document 1: 0.12250586479313998\n",
      "Score for document 2: 1.1668697860065433\n",
      "Score for document 3: 0.13982344777436917\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "\n",
    "class BM25:\n",
    "    def __init__(self, corpus, k1=1.5, b=0.75):\n",
    "        self.corpus = corpus\n",
    "        self.k1 = k1\n",
    "        self.b = b\n",
    "        self.avgdl = sum(len(doc) for doc in corpus) / len(corpus)\n",
    "        self.idf = {}\n",
    "        self.initialize()\n",
    "\n",
    "    def initialize(self):\n",
    "        doc_count = len(self.corpus)\n",
    "        for doc in self.corpus:\n",
    "            for word in set(doc):\n",
    "                if word not in self.idf:\n",
    "                    doc_freq = sum(1 for doc in self.corpus if word in doc)\n",
    "                    self.idf[word] = math.log((doc_count - doc_freq + 0.5) / (doc_freq + 0.5) + 1)\n",
    "\n",
    "    def score(self, query, document):\n",
    "        score = 0\n",
    "        doc_len = len(document)\n",
    "        for word in query:\n",
    "            if word not in self.idf:\n",
    "                continue\n",
    "            tf = document.count(word)\n",
    "            score += (self.idf[word] * tf * (self.k1 + 1)) / (tf + self.k1 * (1 - self.b + self.b * doc_len / self.avgdl))\n",
    "        return score\n",
    "\n",
    "# Example usage:\n",
    "corpus = [\n",
    "    [\"hello\", \"world\", \"hello\", \"bm25\"],\n",
    "    [\"bm25\", \"algorithm\", \"example\"],\n",
    "    [\"implementation\", \"of\", \"bm25\"],\n",
    "]\n",
    "\n",
    "bm25 = BM25(corpus)\n",
    "\n",
    "query = [\"bm25\", \"algorithm\"]\n",
    "for i, doc in enumerate(corpus):\n",
    "    print(f\"Score for document {i+1}: {bm25.score(query, doc)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env-01",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
